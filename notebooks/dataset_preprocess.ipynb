{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tAJYJKBO8_HJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "DATA_DIR = \"/home/idies/workspace/Storage/colemanzhang98/persistent/git_repo/ml-research/datasets/\"\n",
    "df = pd.read_csv(DATA_DIR + 'data.zip', compression='zip', parse_dates=['DATE', 'datadate'])\n",
    "df.columns = map(str.lower, df.columns)\n",
    "sec = ['date', 'datadate', 'permno', 'gvkey', 'sic2']\n",
    "firm_char = ['absacc', 'acc', 'aeavol', 'age', 'agr', 'baspread', 'beta', \n",
    "             'betasq', 'bm', 'bm_ia', 'cash', 'cashdebt', 'cashpr', 'cf', \n",
    "             'cfp', 'cfp_ia', 'chadv', 'chato', 'chatoia', 'chcsho', 'chdrc', \n",
    "             'chempia', 'chinv', 'chmom', 'chobklg', 'chpm', 'chpmia', 'chtx', \n",
    "             'cinvest', 'conv', 'convind', 'count', 'credrat', 'credrat_dwn', \n",
    "             'currat', 'depr', 'divi', 'divo', 'dolvol', 'dy', 'eamonth', \n",
    "             'ear', 'egr', 'ep', 'gma', 'grcapx', 'grgw', 'grltnoa', 'herf', \n",
    "             'hire', 'idiovol', 'ill', 'indmom', 'invest', 'ipo', 'lev', 'lgr', \n",
    "             'maxret', 'mom12m', 'mom1m', 'mom36m', 'mom6m', 'ms', 'mve', \n",
    "             'mve_ia', 'nincr', 'obklg', 'operprof', 'orgcap', 'pchcapx', \n",
    "             'pchcapx_ia', 'pchcurrat', 'pchdepr', 'pchgm_pchsale', 'pchquick', \n",
    "             'pchsale_pchinvt', 'pchsale_pchrect', 'pchsale_pchxsga', \n",
    "             'pchsaleinv', 'pctacc', 'prccq', 'pricedelay', 'ps', 'quick', \n",
    "             'rd', 'rd_mve', 'rd_sale', 'rdbias', 'rdq', 'realestate', \n",
    "             'retcons_neg', 'retcons_pos', 'retvol', 'roaq', 'roavol', 'roe', \n",
    "             'roeq', 'roic', 'rsup', 'salecash', 'saleinv', 'salerec', \n",
    "             'secured', 'securedind', 'sgr', 'sgrvol', 'sin', 'sp', 'spi', \n",
    "             'spii', 'std_dolvol', 'std_turn', 'stdacc', 'stdcf', 'tang', 'tb', \n",
    "             'turn', 'wogw', 'zerotrade'] # 119 firm characteristics\n",
    "\n",
    "crsp_list = ['exchcd', 'dlret', 'dlstcd', 'vol', 'shrout', 'prc', 'ewret', 'ret']\n",
    "import numpy as np\n",
    "df_cols = np.append(np.append(np.asarray(sec), firm_char), crsp_list)\n",
    "df = df[df_cols]\n",
    "df = df.loc[~df.duplicated(subset=['date', 'gvkey'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9001,
     "status": "ok",
     "timestamp": 1572926234653,
     "user": {
      "displayName": "Zhang Coleman",
      "photoUrl": "",
      "userId": "01343579441395491485"
     },
     "user_tz": 300
    },
    "id": "VS8_jazS-x8a",
    "outputId": "fb19848c-81d7-4283-d514-21a1f92f97f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idies/miniconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# Add Research Qutient & Tobin's Q; shift yearly updated characteristic by 6 months\n",
    "q = pd.read_csv(DATA_DIR + \"q.zip\", index_col = 0, parse_dates=[1, 3], compression=\"zip\")\n",
    "rq = pd.read_csv(DATA_DIR + \"rq.zip\", index_col = 0, parse_dates=[1], compression=\"zip\")\n",
    "q['gvkey'] = q['gvkey'].astype(pd.Int64Dtype())\n",
    "q['fyear'] = q['fyear'].astype(pd.Int64Dtype())\n",
    "rq['gvkey'] = rq['gvkey'].astype(pd.Int64Dtype())\n",
    "rq['fyear'] = rq['fyear'].astype(pd.Int64Dtype())\n",
    "pd.set_option(\"display.max_rows\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fyyujW_BHHmI"
   },
   "outputs": [],
   "source": [
    "# q.insert(1, 'date', q['datadate'] + pd.DateOffset(months=6)) # shift annual characteristics by 6 months lag\n",
    "# def q_to_month(group):\n",
    "#     last_yr = group.datadate.max()\n",
    "#     group = group.append(pd.Series({'datadate': last_yr + pd.DateOffset(years=1), \n",
    "#                                     'date': last_yr + pd.DateOffset(years=1) + pd.DateOffset(months=6)}), \n",
    "#                          ignore_index=True)\n",
    "#     group = group.set_index('date')\n",
    "#     group.index += pd.offsets.MonthEnd(0)\n",
    "#     group = group.asfreq(freq='m').ffill(limit=12)\n",
    "#     group = group.iloc[:-1]\n",
    "#     return group\n",
    "# q_ = q.groupby('gvkey', as_index=False).apply(q_to_month).reset_index().drop(\"level_0\", axis=1)\n",
    "# q_['gvkey'] = q_['gvkey'].astype(pd.Int64Dtype())\n",
    "# q_['fyear'] = q_['fyear'].astype(pd.Int64Dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJZ9uRrPUfoa"
   },
   "outputs": [],
   "source": [
    "# rq = rq[~rq.duplicated(subset=['gvkey', 'date'])]\n",
    "# rq.insert(1, 'date', pd.to_datetime(rq['fyear'].astype(str) + '1231') + pd.DateOffset(months=6))\n",
    "# def rq_to_month(group):\n",
    "#     last_yr = group.date.max()\n",
    "#     group = group.append(pd.Series({'date': last_yr + pd.DateOffset(years=1)}), \n",
    "#                          ignore_index=True)\n",
    "#     group = group.set_index('date')\n",
    "#     group.index += pd.offsets.MonthEnd(0)\n",
    "#     group = group.asfreq(freq='m').ffill(limit=12)\n",
    "#     group = group.iloc[:-1]\n",
    "#     return group\n",
    "# rq_ = rq.groupby('gvkey', as_index=False).apply(rq_to_month).reset_index().drop(\"level_0\", axis=1)\n",
    "# rq_['gvkey'] = rq_['gvkey'].astype(pd.Int64Dtype())\n",
    "# rq_['fyear'] = rq_['fyear'].astype(pd.Int64Dtype())\n",
    "# rq_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LvofR1vRe3sO"
   },
   "outputs": [],
   "source": [
    "q.insert(1, 'yyyymm', q['date'].dt.strftime('%Y%m').astype(int))\n",
    "rq.insert(1, 'yyyymm', rq['date'].dt.strftime('%Y%m').astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9lUqIorIyVA"
   },
   "outputs": [],
   "source": [
    "macro = pd.read_excel(DATA_DIR + 'macroecon.xlsx', parse_dates=['yyyymm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hi2LBcL17oYA"
   },
   "outputs": [],
   "source": [
    "macro['dp'] = np.log(macro['D12']) - np.log(macro['Index'])\n",
    "macro['ep'] = np.log(macro['E12']) - np.log(macro['Index'])\n",
    "macro['bm'] = macro['b/m']\n",
    "macro['tms'] = macro['lty'] - macro['tbl']\n",
    "macro['dfy'] = macro['BAA'] - macro['AAA']\n",
    "macro = macro.loc[macro['yyyymm']>=196001, ['yyyymm', 'dp', 'ep', 'bm', 'ntis', 'tbl', 'tms', 'dfy', 'svar']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7OC6sW0fAiWd"
   },
   "outputs": [],
   "source": [
    "df.insert(1, 'yyyymm', df['date'].dt.strftime('%Y%m').astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AKYTq_RyAtkb"
   },
   "outputs": [],
   "source": [
    "# Merge firm char, CRSP with rq, q, and macro economic factors\n",
    "from functools import reduce\n",
    "q_reduced = q.loc[q['gvkey'].notnull(), ['yyyymm', 'gvkey', 'q_tot']].copy()\n",
    "rq_reduced = rq.loc[rq['gvkey'].notnull(), ['yyyymm', 'gvkey', 'aggbeta_lxrd']].copy()\n",
    "dataframes = [df, q_reduced, rq_reduced]\n",
    "df_ = reduce(lambda left, right: pd.merge(left, right, on=['gvkey', 'yyyymm'],\n",
    "                                          how='left'), dataframes)\n",
    "df2 = pd.merge(df_, macro, how='left', on='yyyymm', suffixes=('', '_macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_\n",
    "del df\n",
    "del q\n",
    "del rq\n",
    "del q_reduced\n",
    "del rq_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4cfzeQZ9o__"
   },
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "macro_cols = ['dp', 'ep_macro', 'bm_macro', 'ntis', 'tbl', 'tms', 'dfy', 'svar']\n",
    "cols = [np.asarray(sec), firm_char, macro_cols, np.asarray(['q_tot', 'aggbeta_lxrd']), crsp_list]\n",
    "df_cols = reduce(lambda left, right: np.append(left, right), cols)\n",
    "df2 = df2[df_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column for security returns at T+1\n",
    "df2.insert(1, 'yyyymmdd', df2['date'].dt.strftime('%Y%m%d').astype(int))\n",
    "dates = df2['yyyymmdd'].unique()\n",
    "x = np.sort(dates)\n",
    "x = np.append(x, 20190131)\n",
    "y = df2['yyyymmdd'].values\n",
    "df2.insert(2, 'yyyymmdd+1', x[np.where(y.reshape(y.size, 1) == x)[1]+1])\n",
    "\n",
    "exp_df = pd.merge(df2, df2[['gvkey', 'yyyymmdd', 'ewret', 'ret']], \n",
    "                  left_on=['gvkey', 'yyyymmdd+1'], right_on=['gvkey', 'yyyymmdd'], how='left', suffixes=(\"\", \"+1m\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del exp_df['yyyymmdd']\n",
    "del exp_df['yyyymmdd+1']\n",
    "del exp_df['yyyymmdd+1m']\n",
    "exp_df = exp_df[exp_df['date'] > pd.to_datetime(\"1965-05-31\")] # start from month with sufficient observations\n",
    "del df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firm_char_ = np.sort(np.append(firm_char, np.asarray(['q_tot', 'aggbeta_lxrd'])))\n",
    "exp_df = exp_df.sort_values(by=['date', 'gvkey'])\n",
    "\n",
    "# Rank firm characteristics within period cross-secionally and normalize to [-1, 1]\n",
    "def char_rank(group):\n",
    "    group[firm_char_] = group[firm_char_].rank(pct=True) * 2 - 1\n",
    "    return group\n",
    "\n",
    "for char in firm_char_:\n",
    "    exp_df.insert(exp_df.columns.get_loc(char) + 1, f\"{char}_missing\", np.nan)\n",
    "char_missing = np.array([f\"{char}_missing\" for char in firm_char_])\n",
    "\n",
    "# Fill by cross-secion median by period\n",
    "def fill_missing(group):\n",
    "    group[char_missing] = group[firm_char_].isnull().astype(np.int)\n",
    "    group[firm_char_] = group[firm_char_].fillna(group[firm_char_].median())\n",
    "    return group\n",
    "\n",
    "# Create label based on return at T+1 (performance ranking)\n",
    "def add_label(group):\n",
    "    group = group[group['ret+1m'].notnull()]\n",
    "    group['label'] = group['ret+1m'].rank(ascending=False)\n",
    "    return group\n",
    "\n",
    "exp_df = exp_df.groupby('date').apply(char_rank)\n",
    "exp_df = exp_df.groupby('date').apply(fill_missing)\n",
    "exp_df = exp_df.groupby('date').apply(add_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5lDvbd3gk28b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4abb85fc18f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfirm_char_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirm_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'q_tot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aggbeta_lxrd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfirm_char_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# d1.values on older pandas versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmacro_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumexpr\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "firm_char_ = np.sort(np.append(firm_char, np.asarray(['q_tot', 'aggbeta_lxrd'])))\n",
    "a = exp_df[firm_char_].to_numpy(copy=False) # d1.values on older pandas versions\n",
    "b = exp_df[macro_cols].to_numpy(copy=False)\n",
    "\n",
    "# Create interactions between macroeconomic factors and firm characteristics\n",
    "import numexpr as ne\n",
    "out = ne.evaluate('a3D*b3D',{'a3D':a[:,:,None],'b3D':b[:,None]}).reshape(len(a),-1)\n",
    "df_out = pd.DataFrame(out)\n",
    "df_out.columns = [f\"{i}*{j}\" for i in firm_char_ for j in macro_cols]\n",
    "df_out.index = exp_df.index\n",
    "exp_df = pd.concat([exp_df, df_out], axis=1)\n",
    "\n",
    "cols = [np.asarray(sec), firm_char_, char_missing, df_out.columns.values, \n",
    "        crsp_list, np.asarray(['ewret+1m', 'ret+1m', 'label'])]\n",
    "df_cols = reduce(lambda left, right: np.append(left, right), cols)\n",
    "exp_df = exp_df[df_cols]\n",
    "exp_df = exp_df[~((exp_df['dlstcd'].notnull()) & (exp_df['dlstcd']>400))] # drop delisted companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df.head(100).to_csv(\"/home/idies/workspace/Storage/colemanzhang98/persistent/scratch/header_with_label.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M2YbMp4-KleG"
   },
   "outputs": [],
   "source": [
    "# exp_df.to_csv(\"/home/idies/workspace/Temporary/colemanzhang98/scratch/data_labeled.zip\", compression='zip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PLS\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "pls2 = PLSRegression(n_components=100)\n",
    "exp_df = pd.get_dummies(exp_df, dummy_na=True, columns=['sic2'], drop_first=True)\n",
    "dummy_cols = np.asarray([[col for col in exp_df.columns if \"sic2_\" in col]])\n",
    "cols = [dummy_cols, firm_char_, char_missing, df_out.columns.values]\n",
    "feature_cols = reduce(lambda left, right: np.append(left, right), cols)\n",
    "train = exp_df.loc[exp_df['date'] <= pd.to_datetime(\"1981-06-30\"), :]\n",
    "X = train[feature_cols].fillna(0)\n",
    "y = train['label']\n",
    "pls2.fit(X, y)\n",
    "P = pls2.x_loadings_\n",
    "df_P = pd.DataFrame(P, index=X.columns, columns=[f\"comp_{i}\" for i in range(1, 101)])\n",
    "df_P.to_csv(\"/home/idies/workspace/Storage/colemanzhang98/persistent/scratch/X_loadings.csv\")\n",
    "T = pls2.x_scores_\n",
    "df_T = pd.DataFrame(T, index=train.index, columns=[f\"comp_{i}\" for i in range(1, 101)])\n",
    "output = pd.concat([train[sec], df_T, train[['ret', 'ret+1m', 'label']]], axis=1)\n",
    "output.to_csv(\"/home/idies/workspace/Temporary/colemanzhang98/scratch/reduced.csv.zip\", compression='zip')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of Untitled0.ipynb",
   "provenance": [
    {
     "file_id": "1qlRhLfKvcXcvB4Zelr92XJKJSFD77U02",
     "timestamp": 1572925616043
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
